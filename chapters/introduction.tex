%************************************************
\chapter{Introduction}\label{ch:introduction}
%************************************************
Money makes the world go round. That is why the sales department
of any company is vital to its success. Ben Horowitz correctly
stresses this importance: "The sales organization is the face of the company to the outside world" \cite{bh:2014}

As social media platforms like facebook, Twitter, LinkedIn and Xing
have grown successful, they have become part of this face.
On these platforms, millions of entries are made each day.
500 million tweets were sent on a single day on Twitter in 2013 alone.
All platforms combined result in a huge marketing reach,
making social media channels a huge possibility for sales.
Customer interactions are now possible on a very personal level,
something that seemed nearly impossible a long time ago.
Customer appraisal and shitstorms lie very much near each other.
\newline

In all of this beauty of customer service there is a caveat:
Trying to find the \textit{right} information inside this
flood of data, which is often referred to as noise, is a tiresome
process that needs to be gone through everyday and often by hand.
Tiresome during freetime and even more stressful if it has to be done on the job.
Finding pieces of information which might hint at an interest
in a product are the things are the ones sought after daily by sales representatives.
Such a finding often leads to an attempt at contacting the author of the
entry in question. The information that hints at a consumer interest is commonly
referred to as Opportunity.
\newline

Thus, converting "Noise to Opportunity", is a very common struggle
in sales departments. The principle is usually illustrated with a funnel,
as shown and explained in figure \ref{fig:sales-funnel}.

\marginpar{Converting noise to opportunity is the very tiring, repetitive task
of finding useful information in a heap of thematically
but not practically relevant data}

\begin{figure}[bth]
    %\includegraphics[width=90\linewidth]{gfx/sales-funnel}
    \caption{The sales funnel for reducing noise to opportunity. Too much
    information with a few useful bits in it goes in at the top and gets
    reduced to promising pieces that might be converted to a sales opportunity}
    \label{fig:sales-funnel}
\end{figure}

The bachelor project M1 at the chair of Internet Technologies and Systems
at the Hasso-Plattner-Institute tackled this problem by applying demand-based filtering to it.
With product descriptions of the products in mind that the department wants to sell,
the relevant pieces of information are filtered out and delivered to each employee -
ranked by relevancy. Based on different sales territories,
these pieces can also be routed to different individuals.
\newline

\marginpar{The bachelor project is a two-semester project at HPI,
where 2-7 students work together on a large software system,
often for an external partner. In the process, expertise
for the bachelor thesis is gathered. }

The general principle of reducing information load by applying
demand-based-filtering can also be tailored to fit recruiting processes.
Recruiting may even be mapped roughly on to the problem of selling products.
The \textit{products} are the job vacancies in this case, whereas the
\textit{customers} are the potential employees that need to be found.\\
It is no secret that there is a heavy competition among recruiters for excellent
technical candidates because of their scarcity and it seems a resonable thought
to gain a competitive edge by pre-analyzing technical candidates
before considering them for an interview. Also, it makes sense to apply
some sort of metric for measuring skill, because
"You can't manage what you can't measure"\cite{tdm:1986}.  People-based metrics
need to be seen skeptically, but hiring is such an important decision that it
should be manifested with numbers, because it can severely affect
company success\cite{hk:1998}.
\newline

%As previous studies have shown, the awareness of their source
%code being public increases developer determination
%to produce top quality source code\cite{md:2013}.
%Public source code repositories have grown in importance for recruting
%staff, which shows that there is a practical need for determining
%employee fit to certain positions before making first contact.

\section{Contribution}
% See phil giesess thesis for a very good introduction on what he has built
% take job advertisements and find developers for them
% goal is a system similar to N2O but for recruiters and not for salespeople
%What has been built in this thesis and what has been achieved?
%GitHub provides users with the possibility of
%publicly hosting source code as well as collaborating with other users on a
%project-scale or even an organization-scale. The source code itself as well
%as the whole git history is publicly available and provides a solid base
%for analysis. Because of its widespread adoption, this platform has been chosen
%for the analysis. Of course, the principle of analyzing source code and matching
%it to job postings is very general and could be applied
%to any kind of repository.
In this thesis we will present a platform on which recruiters can easily
gain access to software engineering talents. The recruiters can specify
what kind of position they want to find candidates for, and will receive
suggestions from the userbase that has registered with the application.
The suggestions are based on analyzed open source code repositories.
Github will be the only source of code in our case, but it has proven
to be sufficiently large and well-frequented for our use case.
The analysis metric has been constructed specifically for our use case,
because there were no suitable ones around at the time of writing.

\section{Research Questions} \label{sec:research-questions}
To guide our research, we formulated the following research questions:

\subsection{How can developer skills be measured?}\label{subsec:dev-skill-measurement}
We argue that a measurement metric that is common to most job opening
descriptions must be found. This reduces the need for a lot of customization
on the ad and allows analysis of pre-existing data.
\newline

All developers will be matched against the same job advertisements and thus
they all need to be measured using the same method. The metric that
has been derived from the advertisements will need to be measured
on each developer - provided he or she can provide the necessary data.
Thus the practicability of a metric depends largely on the availability
of measureable data.

\subsection{Can qualified candidates be found automatically?}\label{subsec:measurement-quality}
The metric allows developers to be ranked by suitability for the position.
The qualities of this ranking are ultimately determined by whether
or not the right candidates land at the top of it. This needs to be
verified with real world job candidates and the job opening descriptions
that they applied for


\section{Related Work}

Jennifer Marlow and Laura Dabbish\cite{md:2013} from Carnegie Mellon
University have conducted an extensive study with about
200 participants, and found out that employers value
open source coder profiles greatly (page 4). Further in the document,
the two authors prove that developers are conscious of the fact
that their source code is public and thus try to deliver it with
great care. This is relevant for us for two reasons:
First, it proves that contribution to open source has a relevancy
in hiring and is rewarded with recognition. And second, Marlows and Dabbishs
research hints at the fact that developers trying hard to deliver very
good code, because they are aware of its publicity. Because we will use
exactly this code in our measurements, it is highly relevant that it be of good quality.
Altogether their research has proven that both public sourcecode repositories
are relevant for making recruitment decisions and that open source developers
are aware of this fact and try to deliver their best.
\newline

The suitability of source code analysis for the identification of personal
skillsets has been proven in the master thesis of Philipp Giese.
He built a framework called \textit{Analyzr}\footnote{\url{https://github.com/frontendphil/analyzr}}
that analyzes the complete history from a git or SVN source code repository.
Based on the code, different metrics are calculated, from which statements about
code complexity and refactoring needs can be derived. It is also possible
to make statements about developer capabilites and areas of expertise.
Thus, given a little context about the analyzed source code, it would possible
to say that \glqq Developer X is mainly a backend developer and the single maintainer of module Y\grqq.
\newline

Philipp's development findings are supported by that of
Aftab Iqbal and Michael Hausenblas, who have analyzed different
source code repositories for common developers\cite{ih:2012}.
They have done so using relatively little local code analysis and relied
on on-the-fly analysis from retrieved RDF data. Their work
has made it possible to find out whether different open source projects shared developers
and contained useful methods of retrieving authors and eleminating duplicates
caused by different e-mail addresses, for example.
One of their primary sources of code was\textit{sourceforge}, a site that was
popular for open source code hosting before GitHub became popular.
Now, in 2015, sourceforge has more or less disappeared from the map of open
source developers and does not host a lot of projects of relevance anymore.

Finally, a japanese research group at the Kobe University in Tokio, seems
to display great interest in software analytics\cite{mn:2011}. Shinsuke Matsumoto and Masahide Nakamura
have built a web service that allowed the analysis of any SVN or git source code repository.
They were specifically interested in creating a platform for other researchers to
contribute their source code metrics to. The metrics are programming-language agnostic
and very general. Unfortunately the code was badly documented and if there was documentation
to be found, it was written in japanese. Matsumotos and Nakamuras paper
went into deep technical detail of the inner workings of their platform.
This knowledge was particularly helpful in the forming of an architecture for ours.